{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78626bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, f1_score\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8588f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['HR_mean','HR_std','meanNN','SDNN','medianNN','meanSD','SDSD','RMSSD','pNN20','pNN50','TINN','LF','HF','ULF','VLF','LFHF',\n",
    "         'total_power','lfp','hfp','SD1','SD2','pA','pQ','ApEn','shanEn','D2','subject','label']\n",
    "\n",
    "WINDOW_SIZE = '120'\n",
    "\n",
    "\n",
    "NOISE = ['bp_time_ens']\n",
    "subjects = [2,3,4,5,6,7,8,9,10,11,13,14,15,16,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851fe8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, feats, testset_num):\n",
    "    print(\"testset num: \",testset_num)\n",
    "    df = pd.read_csv(path, index_col = 0)\n",
    "    \n",
    "    df = df[feats]\n",
    "\n",
    "    train_df = df.loc[df['subject'] != testset_num]\n",
    "    test_df =  df.loc[df['subject'] == testset_num]\n",
    "\n",
    "    del train_df['subject']\n",
    "    del test_df['subject']\n",
    "    del df['subject']\n",
    "\n",
    "    \n",
    "    X_train = train_df.drop('label', axis=1).values\n",
    "    y_train = train_df['label'].values   \n",
    "    X_test = test_df.drop('label', axis=1).values\n",
    "    y_test = test_df['label'].values    \n",
    "    \n",
    "    return df, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b77ec",
   "metadata": {},
   "source": [
    " -\n",
    "\n",
    "\n",
    "\n",
    " # Machine learning\n",
    "\n",
    "\n",
    "\n",
    " +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69328a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = tree.DecisionTreeClassifier(random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ACC = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    fpr,tpr, roc_auc = dict(), dict(), dict()\n",
    "    n_classes = 4\n",
    "    \n",
    "    \n",
    "    y_pred = np.eye(n_classes)[y_pred]\n",
    "    y_test = np.eye(n_classes)[y_test]  # one-hot-vector\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    AUC = np.array(list(roc_auc.values())).mean()\n",
    "    F1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro')  \n",
    "    \n",
    "    return AUC, F1, ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972e59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ACC = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    fpr,tpr, roc_auc = dict(), dict(), dict()\n",
    "    n_classes = 4\n",
    "    \n",
    "    y_pred = np.eye(n_classes)[y_pred]\n",
    "    y_test = np.eye(n_classes)[y_test]  # one-hot-vector\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    AUC = np.array(list(roc_auc.values())).mean()\n",
    "    F1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro')  \n",
    "    \n",
    "    return AUC, F1, ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ce398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AB_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = AdaBoostClassifier(random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ACC = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    fpr,tpr, roc_auc = dict(), dict(), dict()\n",
    "    n_classes = 4\n",
    "    \n",
    "    y_pred = np.eye(n_classes)[y_pred]\n",
    "    y_test = np.eye(n_classes)[y_test]  # one-hot-vector\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    AUC = np.array(list(roc_auc.values())).mean()\n",
    "    F1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro')  \n",
    "    \n",
    "    return AUC, F1, ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5166d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KN_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=9)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ACC = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    fpr,tpr, roc_auc = dict(), dict(), dict()\n",
    "    n_classes = 4\n",
    "\n",
    "    y_pred = np.eye(n_classes)[y_pred]\n",
    "    y_test = np.eye(n_classes)[y_test]  # one-hot-vector\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    AUC = np.array(list(roc_auc.values())).mean()\n",
    "    F1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro')  \n",
    "    \n",
    "    return AUC, F1, ACC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a65029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ACC = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    fpr,tpr, roc_auc = dict(), dict(), dict()\n",
    "    n_classes = 4\n",
    "    \n",
    "    y_pred = np.eye(n_classes)[y_pred]\n",
    "    y_test = np.eye(n_classes)[y_test]  # one-hot-vector\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    AUC = np.array(list(roc_auc.values())).mean()\n",
    "    F1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro')  \n",
    "    \n",
    "    \n",
    "    return AUC, F1, ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b50c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = svm.SVC()\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ACC = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    fpr,tpr, roc_auc = dict(), dict(), dict()\n",
    "    n_classes = 4\n",
    "    \n",
    "    y_pred = np.eye(n_classes)[y_pred]\n",
    "    y_test = np.eye(n_classes)[y_test]  # one-hot-vector\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    AUC = np.array(list(roc_auc.values())).mean()\n",
    "    F1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro')  \n",
    "    \n",
    "    \n",
    "    return AUC, F1, ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc81c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = GradientBoostingClassifier(random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ACC = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    fpr,tpr, roc_auc = dict(), dict(), dict()\n",
    "    n_classes = 4\n",
    "    \n",
    "    y_pred = np.eye(n_classes)[y_pred]\n",
    "    y_test = np.eye(n_classes)[y_test]  # one-hot-vector\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    AUC = np.array(list(roc_auc.values())).mean()\n",
    "    F1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro')  \n",
    "    \n",
    "    \n",
    "    return AUC, F1, ACC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70acd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "feats = ['HR_mean','HR_std','meanNN','SDNN','medianNN','meanSD','SDSD','RMSSD','pNN20','pNN50','TINN','LF','HF','ULF','VLF','LFHF',\n",
    "         'total_power','SD1','SD2','pA','pQ','ApEn','shanEn','D2','subject','label']      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c40aa6",
   "metadata": {},
   "source": [
    "# +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d983d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset num:  2\n",
      "testset num:  3\n",
      "testset num:  4\n",
      "testset num:  5\n",
      "testset num:  6\n",
      "testset num:  7\n",
      "testset num:  8\n",
      "testset num:  9\n",
      "testset num:  10\n",
      "testset num:  11\n",
      "testset num:  13\n",
      "testset num:  14\n",
      "testset num:  15\n",
      "testset num:  16\n",
      "testset num:  17\n",
      "DONE:  bp_time_ens\n"
     ]
    }
   ],
   "source": [
    "for n in NOISE:\n",
    "    \n",
    "    #path = '27_features_ppg_9/data_merged_' + n + WINDOW_SIZE + '.csv'\n",
    "    #result_path_all = 'result/BGM2/all_features_' + n + WINDOW_SIZE + '.csv'\n",
    "\n",
    "    path = '27_features_ppg_test_4/LMM/data_merged_' + n + WINDOW_SIZE + '.csv'\n",
    "    result_path_all = 'result_4/LMM/all_features_' + n + WINDOW_SIZE + '.csv'\n",
    "    result_path_all = 'result_quad.csv'\n",
    "\n",
    "    DT_AUC, DT_F1, DT_ACC = [], [], []\n",
    "    RF_AUC, RF_F1, RF_ACC = [], [], []\n",
    "    AB_AUC, AB_F1, AB_ACC = [], [], []\n",
    "    KN_AUC, KN_F1, KN_ACC = [], [], []\n",
    "    LDA_AUC, LDA_F1, LDA_ACC = [], [], []\n",
    "    SVM_AUC, SVM_F1, SVM_ACC = [], [], []\n",
    "    GB_AUC, GB_F1, GB_ACC = [], [], []\n",
    "\n",
    "    for sub in subjects:\n",
    "    \n",
    "        df, X_train, y_train, X_test, y_test = read_csv(path, feats, sub)\n",
    "        df.fillna(0)\n",
    "        # Normalization\n",
    "        sc = StandardScaler()  \n",
    "        X_train = sc.fit_transform(X_train)  \n",
    "        X_test = sc.transform(X_test)  \n",
    "\n",
    "    \n",
    "        auc_dt, f1_dt, acc_dt = DT_model(X_train, y_train, X_test, y_test)\n",
    "        auc_rf, f1_rf, acc_rf = RF_model(X_train, y_train, X_test, y_test)\n",
    "        auc_ab, f1_ab, acc_ab = AB_model(X_train, y_train, X_test, y_test)\n",
    "        auc_kn, f1_kn, acc_kn = KN_model(X_train, y_train, X_test, y_test)\n",
    "        auc_lda, f1_lda, acc_lda = LDA_model(X_train, y_train, X_test, y_test)\n",
    "        auc_svm, f1_svm, acc_svm = SVM_model(X_train, y_train, X_test, y_test)\n",
    "        auc_gb, f1_gb, acc_gb = GB_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        DT_AUC.append(auc_dt)\n",
    "        DT_F1.append(f1_dt)\n",
    "        DT_ACC.append(acc_dt)\n",
    "        RF_AUC.append(auc_rf)\n",
    "        RF_F1.append(f1_rf)\n",
    "        RF_ACC.append(acc_rf)\n",
    "        AB_AUC.append(auc_ab)\n",
    "        AB_F1.append(f1_ab)\n",
    "        AB_ACC.append(acc_ab)\n",
    "        KN_AUC.append(auc_kn)\n",
    "        KN_F1.append(f1_kn)\n",
    "        KN_ACC.append(f1_kn)\n",
    "        LDA_AUC.append(auc_lda)\n",
    "        LDA_F1.append(f1_lda)\n",
    "        LDA_ACC.append(acc_lda)\n",
    "        SVM_AUC.append(auc_svm)\n",
    "        SVM_F1.append(f1_svm)\n",
    "        SVM_ACC.append(acc_svm)\n",
    "        GB_AUC.append(auc_gb)\n",
    "        GB_F1.append(f1_gb)\n",
    "        GB_ACC.append(acc_gb)\n",
    "    \n",
    "\n",
    "    with open(result_path_all, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        writer.writerow(['subject','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S13','S14','S15','S16','S17','total'])\n",
    "        writer.writerow(['DT_AUC'] + DT_AUC + [np.mean(DT_AUC)])\n",
    "        writer.writerow(['RF_AUC'] + RF_AUC + [np.mean(RF_AUC)])\n",
    "        writer.writerow(['AB_AUC'] + AB_AUC + [np.mean(AB_AUC)])\n",
    "        writer.writerow(['KN_AUC'] + KN_AUC + [np.mean(KN_AUC)])\n",
    "        writer.writerow(['LDA_AUC'] + LDA_AUC + [np.mean(LDA_AUC)])\n",
    "        writer.writerow(['SVM_AUC'] + SVM_AUC + [np.mean(SVM_AUC)])\n",
    "        writer.writerow(['GB_AUC'] + GB_AUC + [np.mean(GB_AUC)])\n",
    "        writer.writerow(['DT_F1'] + DT_F1 + [np.mean(DT_F1)])\n",
    "        writer.writerow(['RF_F1'] + RF_F1 + [np.mean(RF_F1)])\n",
    "        writer.writerow(['AB_F1'] + AB_F1 + [np.mean(AB_F1)])\n",
    "        writer.writerow(['KN_F1'] + KN_F1 + [np.mean(KN_F1)])\n",
    "        writer.writerow(['LDA_F1'] + LDA_F1 + [np.mean(LDA_F1)])\n",
    "        writer.writerow(['SVM_F1'] + SVM_F1 + [np.mean(SVM_F1)])\n",
    "        writer.writerow(['GB_F1'] + GB_F1 + [np.mean(GB_F1)])\n",
    "        writer.writerow(['DT_ACC'] + DT_ACC + [np.mean(DT_ACC)])\n",
    "        writer.writerow(['RF_ACC'] + RF_ACC + [np.mean(RF_ACC)])\n",
    "        writer.writerow(['AB_ACC'] + AB_ACC + [np.mean(AB_ACC)])\n",
    "        writer.writerow(['KN_ACC'] + KN_ACC + [np.mean(KN_ACC)])\n",
    "        writer.writerow(['LDA_ACC'] + LDA_ACC + [np.mean(LDA_ACC)])\n",
    "        writer.writerow(['SVM_ACC'] + SVM_ACC + [np.mean(SVM_ACC)])\n",
    "        writer.writerow(['GB_ACC'] + GB_ACC + [np.mean(GB_ACC)])\n",
    "\n",
    "\n",
    "        file.close()\n",
    " \n",
    "    print(\"DONE: \",n)\n",
    "# -\n",
    "# #### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
