{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERXazBF6JHw0"
   },
   "source": [
    "#**09-2 순환 신경망으로 IMDB 리뷰 분류하기**\n",
    "\n",
    "# IMDB 리뷰 데이터셋\n",
    "> IMDB 리뷰 데이터 셋은 감상평에 따라 긍정과 부정으로 분류해 놓은 데이터 셋으로 총 50000개의 샘플을 훈련 데이터와 테스터 데이터에 25000개씩 나눔\n",
    "\n",
    "> 자연어 처리(natural language processing, NPL)는 컴퓨터를 사용해 인간의 언어를 처리하는 분야\n",
    "- 자연어 처리 분야에서는 훈련 데이터를 종종 말뭉치(corpus)라고 부름\n",
    " -IMDV 데이터 셋은 하나의 말뭉치에 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfuxsGTsSeQq"
   },
   "source": [
    "> 컴퓨터에서 처리하는 모든 것은 숫자 데이터이므로, 텍스트 데이터의 경우 단어를 숫자 데이터로 바꾸기 위해 일반적으로 등장하는 단어마다 고유한 정수를 부여하는 방법을 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blbiiE0WSwBH"
   },
   "source": [
    "예시\n",
    "\n",
    "<pre>He follows the cat. He loves the cat.\n",
    "10   11    12  13   10   14   12 13</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmu5238fUNTR"
   },
   "source": [
    "> 동일한 단어에는 동일한 정수가 매핑되고, 매핑되는 정수는 단어의 의미나 크기와 관련 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKBh67iPUlR2"
   },
   "source": [
    "> 일반적으로 영어 문장은 모두 소문자로 바꾸고 구둣점을 삭제한 다음 공백을 기준으로 분리\n",
    "- 이렇게 분리된 단어를 토큰(token)이라고 부름\n",
    "- 하나의 샘플은 여러 개의 토큰으로 이루어져 있고 1개의 토큰이 한개의 타임스텝에 해당\n",
    "\n",
    "> 한글은 조사가 발달해서 공백으로 나누는 것만으로는 부족해서 일반적으로 형태소 분석을 통해 토큰을 만듬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_ZpMGzKVaNS"
   },
   "source": [
    "> 토큰에 할당하는 정수 중에 몇 개는 특정한 용도로 예약되어 있는 경우가 많음\n",
    "- ex) 0은 패딩, 1은 문장의 시작, 2는 어휘 사전에 없는 토큰 등\n",
    " - 훈련 세트에서 고유한 단어를 뽑아 만든 목록을 어휘 사전이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_mVznqfXpdr"
   },
   "source": [
    "> 실제 IMDB 데이터 셋은 영어로된 문장이지만 텐서플로에는 이미 정수로 바꾼 데이터가 포함됨\n",
    "- 전체 데이터셋에서 가장 자주 등장하는 단어 300개만 사용하기 위해 load_data() 함수의 num_words 매개변수를 300으로 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10387,
     "status": "ok",
     "timestamp": 1707065592740,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "pWDENEF1X630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yc_hur\\anaconda3\\envs\\test01\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행마다 동일한 결과를 얻기 위해 케라스에 랜덤 시드를 사용하고 텐서플로 연산을 결정적으로 만듭니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(train_input, train_target), (test_input, test_target) = imdb.load_data(\n",
    "    num_words=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707065592740,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "0OHTbI-uYAny",
    "outputId": "f7c0ced5-a50b-4ae0-fb84-e697ff85ea95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 세트와 테스트 세트 크기 확인\n",
    "print(train_input.shape, test_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdpB7Y2XZlhB"
   },
   "source": [
    "> IMDB 데이터 셋의 배열이 1차원인 이유는 IMDB 리뷰 텍스트는 길이가 제각각 이므로 고정 크기의 2차원 배열에 담기 보다는 리뷰마다 별도의 파이썬 리스트로 담아야 메모리를 효율적으로 사용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3LcfRljePl_"
   },
   "source": [
    "> 즉 이 데이터는 개별 리뷰를 담은 파이썬 리스트 객체로 이루어진 넘파이 배열임\n",
    "- 넘파이 배열은 정수나 실수 외에도 파이썬 객체를 담을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707065592741,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "N2ZOCUsFZa2Q",
    "outputId": "579ecfd8-3f31-42f2-c973-5f7c2759e4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 리뷰의 길이 출력\n",
    "print(len(train_input[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOuK_hyKegJl"
   },
   "source": [
    "> 첫 번째 리뷰는 218개의 토큰으로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707065592741,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "BosLSefNeeUB",
    "outputId": "0c2c8088-001e-41e7-daa2-dc8dd0fd8c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    }
   ],
   "source": [
    "# 두번째 리뷰의 길이 출력\n",
    "print(len(train_input[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_bDmhBCgR8I"
   },
   "source": [
    "> 리뷰마다 각각 길이가 다르며, 하나의 리뷰가 하나의 샘플이 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707065592741,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "EyJmtNW1eoJT",
    "outputId": "50a2851b-c952-40b1-e310-e7703bf941ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 2, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 2, 284, 5, 150, 4, 172, 112, 167, 2, 2, 2, 39, 4, 172, 2, 2, 17, 2, 38, 13, 2, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 2, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 2, 12, 8, 2, 8, 106, 5, 4, 2, 2, 16, 2, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 2, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 7, 4, 2, 2, 13, 104, 88, 4, 2, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 2, 26, 2, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 리뷰 내용 출력\n",
    "print(train_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI9pOa75gfnf"
   },
   "source": [
    "> 텐서플로에 있는 IMDB 데이터는 이밎 정수로 변환 되어 있음\n",
    "- 어휘 사전에는 500개만 들어가도록 지정했기 때문에 어휘 사전에 없는 단어는 모두 2로 표시됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707065592741,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "frnbvqfvgeRy",
    "outputId": "03ae36e5-fa7f-485b-d14b-86f0680c6125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 타깃 데이터 출력\n",
    "print(train_target[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbJzPetHg2l9"
   },
   "source": [
    "> 해결할 문제는 리뷰가 긍정인지 부정인지 판단하는 것이므로 이진 분류\n",
    "- 타깃값은 0(부정), 1(긍정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1707065593448,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "uKhYm4CYg0KP"
   },
   "outputs": [],
   "source": [
    "# 훈련 세트에서 검증 세트 떼기\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_input, val_input, train_target, val_target = train_test_split(\n",
    "    train_input, train_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3uGvR6JmgWS"
   },
   "source": [
    "> 각 리뷰의 길이를 계산해 넘파이 배열에 저장\n",
    "- 평균적인 리뷰의 길이와 가장 짧은 리뷰의 길이 그리고 가장 긴 리뷰의 길이를 확인하기 위해\n",
    "- 넘파이 리스트 내포를 사용해 train_input의 원소를 순회하면서 길이를 재도록 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707065593448,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "W_zsrDjYhX0j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lengths = np.array([len(x) for x in train_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEFR43mTm_cJ"
   },
   "source": [
    "> 넘파이 mean() 함수와 median() 함수를 사용해 리뷰 길이의 평균과 중간값 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707065593448,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "em0Av5wTm85j",
    "outputId": "67a4b790-da21-4ba3-bcb7-bed12c3e88ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.00925 178.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(lengths), np.median(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-UFaxHdnOx3"
   },
   "source": [
    "> 리뷰의 평균 단어 개수는 239, 중간값은 178인 것으로 보아 한쪽에 치우친 분포를 보일 것으로 예상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707065593448,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "9i6-ZamKnL6L",
    "outputId": "132bdcbb-b6cb-4998-a1cc-0bd05be2aa18"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lengths 배열을 히스토그램으로 표현\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lengths)\n",
    "plt.xlabel('lengths')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSnNhU0Nx4-O"
   },
   "source": [
    "> 대부분의 리뷰 길이는 300 미만, 평균이 중간값보다 높은 이유는 오른쪽 끝에 아주 큰 데이터가 존재하기 때문\n",
    "\n",
    "> 리뷰는 대부분 짧아서 이 예제에서는 중간값보다 훨씬 짧은 100개의 단어만 사용\n",
    "- 하지만, 여전히 100개의 단어보다 작은 리뷰가 존재\n",
    "- 이런 리뷰들의 길이를 100에 맞추기 위해 패딩이 필요함\n",
    " - 보통 패딩을 나타내는 토큰으로는 0을 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWH5DkOXyhNH"
   },
   "source": [
    ">케라스는 시퀸스 데이터의 길이를 맞추는 pad_sequences() 함수를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1707065594002,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "jom1Xy-Pnq_A"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_seq = pad_sequences(train_input, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF_rzcn0y_LU"
   },
   "source": [
    "> maxlen에 원하는 길이를 지정하면 이보다 긴 경우는 잘라내고 짧은 경우는 0으로 패딩을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707065594003,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "eYNsvkVqy7s7",
    "outputId": "3fef4c08-8dfd-4dc1-8847-0e1ddc2a6791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n"
     ]
    }
   ],
   "source": [
    "# train_seq 크기 확인\n",
    "print(train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707065595282,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "w6mU6vMbzKyK",
    "outputId": "72a2669c-6f0e-440d-e64c-4e313ca0b762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10   4  20   9   2   2   2   5  45   6   2   2  33 269   8   2 142   2\n",
      "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
      "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
      "   2   7   2   2 188   2 103  14  31  10  10   2   7   2   5   2  80  91\n",
      "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
      "   6   2  46   7  14  20  10  10   2 158]\n"
     ]
    }
   ],
   "source": [
    "# train_seq의 첫번째 원소 출력\n",
    "print(train_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmsXJoMsz93h"
   },
   "source": [
    "> 샘플의 앞 뒤에 0이 없는 것으로 보아 100보다 긴 샘플이었을 것으로 예상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707065595282,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "LtI4Ieziz3MW",
    "outputId": "bd2f00d8-98d3-48da-bffd-0199f33a4a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 46, 7, 14, 20, 10, 10, 2, 158]\n"
     ]
    }
   ],
   "source": [
    "# train_input에 있는 원본 샘플의 끝 확인\n",
    "print(train_input[0][-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF_YX1eb02-o"
   },
   "source": [
    "> train_input[0]의 마지막 10개의 토큰이 train_seq[0]의 출력값과 일치하는 것으로 보아 샘플의 앞부분이 잘렸다는것을 짐작할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lhym111E1KK9"
   },
   "source": [
    "> pad_sequences() 함수는 기본으로 maxlen보다 긴 시퀀스의 앞부분을 자름\n",
    "- 일반적으로 시퀀스의 뒷부분의 정보가 더 유용하리라 기대하기 때문\n",
    " - 영화 리뷰 끝에 결정적인 소감을 말할 가능성이 높다고 판단해서\n",
    "- 만약, 시퀀스의 뒷부분을 잘라내고 싶다면 pad_sequences() 함수의 truncating 매개변수 값을 기본값 'pre'가 아닌 'post'로 바꾸면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707065599070,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "zoisCpVH0RFb",
    "outputId": "dcfaa0da-2f37-4f3e-cc4e-b75eb2708708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2   2   2 183  10\n",
      "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
      "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
      "   2  95  14 238  56 129   2  10  10  21   2  94   2   2   2   2  11 190\n",
      "  24   2   2   7  94 205   2  10  10  87   2  34  49   2   7   2   2   2\n",
      "   2   2 290   2  46  48  64  18   4   2]\n"
     ]
    }
   ],
   "source": [
    "# train_seq의 여섯번째 샘플 출력\n",
    "print(train_seq[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BldWfeef3wKn"
   },
   "source": [
    "> 앞부분에 0이 존재하는 것으로 보아 이 샘플의 길이는 100이 안됨\n",
    "- 역시 같은 이유로 패딩 토큰은 시퀀스의 뒤가 아닌 앞 부분에 추가됨\n",
    " - 시퀀스의 마지막에 있는 단어가 셀의 은닉 상태에 가장 큰 영향을 미치므로 마지막에 패딩을 추가하는 것은 일반적으로 선호 X\n",
    "- pad_sequences ()함수의 padding 매개변수를 기본갓 'pre'가 아닌 'post'로 바꾸면 샘플의 뒷 부분에 패딩 추가 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707065599070,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "8uiUMpaD4VSk"
   },
   "outputs": [],
   "source": [
    "# 검증 세트의 길이 100\n",
    "val_seq = pad_sequences(val_input, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehKZNo9z4d7-"
   },
   "source": [
    "# 순환 신경망 만들기\n",
    "> 케라스가 제공하는 가장 간단한 순환층 클래스는 SimpleRNN 클래스\n",
    "- IMDB 리뷰 분류 문제는 이진 분류이므로 마지막 출력층은 1개의 뉴런을 가지고 시그모이드 함수 사용\n",
    "\n",
    ">Sequential 클래스는 순환신경망을 만드는 용도 X\n",
    "- 순환 신경망 뿐만 아니라 합성곱 신경망이나 일반적인 인공 신경망 모델을 모두 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1707065602133,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "NYmJBlKX3tPX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yc_hur\\anaconda3\\envs\\test01\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.SimpleRNN(8, input_shape=(100, 300)))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_LE3Hts5cOi"
   },
   "source": [
    "> 이 코드는 지금까지 보았던 구성과 매우 비슷\n",
    "- 달라진 것은 Dense나 Conv2D 클래스 대신 SimpleRNN 클래스를 사용\n",
    " - 첫 번째 매개변수에는 사용할 뉴런의 개수를 지정하고 input_shape에 입력 차원을 (100, 300)으로 지정함\n",
    "- 순환층도 당연히 활성화 함수를 사용 해야함\n",
    " - SimpleRNN 클래스의 activation 매개변수의 기본값은 'tanh'로 하이퍼볼릭 탄젠트 함수 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgBCcamg-4-8"
   },
   "source": [
    "> inputshape의 입력 차원\n",
    "- 첫 번째 차원인 100은 앞서 샘플의 길이를 100으로 지정했기 때문\n",
    "- 두 번째 차원인 300은?\n",
    "\n",
    "> train_seq와 val_seq에는 큰 문제가 존재\n",
    " - 토큰을 정수로 변환한 이 데이터를 신경망에 주입하면 큰 정수가 활성화 출력을 만들기 때문\n",
    "  - 분명히 이 정수 사이에는 어떤 관련이 없음 (20번 토큰을 10번 토큰보다 중요시해야 할 이유X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzhCF25KhOiY"
   },
   "source": [
    "> 단순한 정숫값을 신경망에 입력하기 위한 다른 방식 : 원-핫 인코딩\n",
    "- 정숫값에 있는 크기 속성을 없애고 각 정수를 고유하게 표현 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vquVRHgOiHXJ"
   },
   "source": [
    "> ex) train_seq[0]의 첫 번째 토큰인 10을 원-핫 인코딩으로 바꾸면 0 0 0 0 0 0 0 0 0 0 1 ... 0 이 됨\n",
    "- 열 한번째 원소만 1이고 나머지는 모두 0인 배열\n",
    "- imdb.load_data() 함수에서 300개의 단어만 사용하도록 지정했기 때문에 고유한 단어는 모두 300개, 즉 훈련 데이터에 포함될 수 있는 정숫값의 범위는 0(패딩 토큰)에서 499까지이므로 이 범위를 원-핫 인코딩으로 표현하려면 배열의 길이가 300이어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtU2gmX5imNi"
   },
   "source": [
    "> \"I am a boy\"에 있는 각 단어를 숫자 3개를 사용해 표현하는 것 처럼 토큰마다 300개의 숫자를 사용해 표현하는 것, 다만 300개 중에 하나만 1이고 나머지는 모두 0으로 만들어 정수 사이에 있던 크기 속성을 없애는 원-핫 인코딩을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QtGKtC7j4M1"
   },
   "source": [
    "> 케라스에는 원-핫 인코딩을 위한 유틸리티 제공\n",
    "- keras.utils 패키지 아래에 있는 to_categorical() 함수는 정수 배열을 입력하면 자동으로 원-핫 인코딩된 배열을 반환해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1365,
     "status": "ok",
     "timestamp": 1707065603497,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "ghr8hOZi5XI7"
   },
   "outputs": [],
   "source": [
    "train_oh = keras.utils.to_categorical(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707065603497,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "0F4twjTIkWCs",
    "outputId": "690da1dc-fe57-4dc0-872c-6f45daed140d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100, 300)\n"
     ]
    }
   ],
   "source": [
    "# train_seq을 원-핫 인코딩한 train_oh 배열의 크기 출력\n",
    "print(train_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdpPmE_XktXo"
   },
   "source": [
    "> 정수 하나마다 모두 300차원의 배열로 변경되었기 때문에 (20000, 100)크기가 (20000, 100, 300) 크기로 바뀜\n",
    "\n",
    "> 이렇게 샘플 데이터의 크기가 1차원 정수 배열(100, )에서 2차원 배열(100, 300)으로 바꿔야 하므로 SimpleRNN 클래스의 input_shape 매개변수의 값을 (100, 300)으로 지정한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707065603497,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "3vm_6Ie_kfCJ",
    "outputId": "b8c42554-9521-4cc7-fb9e-963f237ce301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# train_oh의 첫 번째 샘플의 첫 번째 토큰 10이 인코딩 되었는지 확인\n",
    "print(train_oh[0][0][:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIz8OgIYlhpX"
   },
   "source": [
    "> 12개의 원소를 출력해보면 11번째 원소만 1이고 나머지 원소는 0인 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707065603497,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "rWHEdiNolcaL",
    "outputId": "734b08ce-c073-40e5-ca9a-efeb95e81c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# train_oh의 모든 원소의 합 출력\n",
    "print(np.sum(train_oh[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eS_IaOeql77t"
   },
   "source": [
    "> 모든 원소의 합이 1인 것으로 보아 11번째 원소를 제외한 나머지 모든 원소가 0인 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1707065605418,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "tp-9GCA6lyvN"
   },
   "outputs": [],
   "source": [
    "# 같은 방식으로 val_seq도 원-핫 인코딩\n",
    "val_oh = keras.utils.to_categorical(val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707065605419,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "EDjXt9jHmNst",
    "outputId": "93bbe119-bd1a-4273-ebcd-fdef902cbe8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 8)                 2472      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2481 (9.69 KB)\n",
      "Trainable params: 2481 (9.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 앞서 만든 모델의 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDIpv-7IpxwR"
   },
   "source": [
    "> SimpleRNN에 전달한 샘플의 크기는 (100,300)이지만 이 순환층은 마지막 타임스텝의 은닉상태만 출력하기 때문에 출력 크기가 순환층의 뉴런 개수와 동일한 8임을 확인할 수 있음\n",
    "\n",
    "> 순환층에 사용된 모델 파라미터의 개수\n",
    "- 입력 토큰은 300차원의 원-핫 인코딩 배열, 이배열이 순환층의 뉴런 8개와 완전히 연결되기 때문에 300 x 8 = 2400개의 가중치가 있음\n",
    "- 순환층의 은닉 상태는 다시 다음 타임스텝에 사용되기 위해 또 다른 가중치와 곱해짐, 이 은닉 상태도 순환층의 뉴런과 완전히 연결되기 때문에 8(은닉상태 크기) x 8(뉴런 개수) = 64개의 가중치가 필요함\n",
    "- 마지막으로 뉴런마다 하나의 절편이 있기 때문에 모두 4000 + 64 + 8 = 4072개의 모델 파라미터가 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEQaoy9GxIRw"
   },
   "source": [
    "# 순환 신경망 훈련하기\n",
    "\n",
    "케라스 API를 사용하는 장점 덕분에 순환 신경망의 훈련은 다른 신경망들과 다르지 않음\n",
    "- 다음 코드처럼 모델을 컴파일하고 훈련하는 전체 구조가 동일함\n",
    " - 아래 예시에서는 기본 RMSprop의 학습률 0.001을 사용하지 않기 위해 별도의 RMSprop 객체를 만들어 학습률을 0.0001로 지정\n",
    " - 에포크 횟수를 100으로 늘리고 배치 크기는 64로 설정\n",
    " - 그 밖에 체크포인트와 조기 종료를 구성하는 코드는 거의 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgx7VRmxozPH"
   },
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model.compile(optimizer=rmsprop, loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5',\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_oh, train_target, epochs=100, batch_size=64,\n",
    "                    validation_data=(val_oh, val_target),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaCqRtNB6IK0"
   },
   "source": [
    "> 책에서의 결과: 훈련은 35번째 에포크에서 조기 종료되었고 검증 세트에 대한 정확도는 약 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1707065369437,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "6xn5_ihg3Jp_",
    "outputId": "5de9b1d1-3e35-47c2-9eb2-648bcd5798de"
   },
   "outputs": [],
   "source": [
    "# 훈련손실과 검증 손실을 그래프로 그려서 훈련과정 살표보기\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlael('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJbuaxmo7S2v"
   },
   "source": [
    "> 훈련 손실은 꾸준히 감소하고 있지만 검증 손실은 대략 스무번째 에포크에서 감소가 둔해지고 있음\n",
    "- 적절한 에포크에서 훈련을 멈춘 것이 확인됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUQBqqY27g0f"
   },
   "source": [
    "> 이 작업을 위해 입력 데이터를 원-핫 인코딩으로 변환함\n",
    "\n",
    "> 원-핫 인코딩의 단점은 입력 데이터가 엄청 커진다는 점\n",
    "- 실제로 train_seq 배열과 train_oh 배열의 nbytes 속성을 출력하여 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1707047114610,
     "user": {
      "displayName": "유찬",
      "userId": "05761325302258896347"
     },
     "user_tz": -540
    },
    "id": "hODocgIY7OuQ",
    "outputId": "9bb9b9b7-48ec-433b-8f9b-69256d0e773e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000000 4000000000\n"
     ]
    }
   ],
   "source": [
    "print(train_seq.nbytes, train_oh.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q36luMd17_G4"
   },
   "source": [
    "> 토큰 1개를 300차원으로 늘렸기 때문에 대략 300배가 커짐\n",
    "- 훈련 데이터가 커질수록 더 문제가 될 것으로 예상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_e4X2XqZ8H0j"
   },
   "source": [
    "# 단어 임베딩을 사용하기\n",
    "\n",
    "> 순환 신경망에서 텍스트를 처리할 때 즐겨 사용하는 방법은 단어 임베딩(word embeding)임\n",
    "- 단어 임베딩은 각 단어를 고정된 크기의 실수 벡터로 바꿔줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj7qvkr9IvGC"
   },
   "source": [
    "예시\n",
    "<pre>'cat'의 단어 임베딩 벡터\n",
    "0.2 0.1 1.3 0.8 0.2 0.4 1.1 0.9 0.2 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIen3yAJJDSE"
   },
   "source": [
    "> 이런 단어 임베딩으로 만들어진 벡터는 원-핫 인코딩된 벡터보다 훨씬 의미 있는 값으로 채워져 있기 때문에 자연어 처리에서더 좋은 성능을 내는 경우가 많음\n",
    "- keras.layers 패키지 아래 Embedding 클래스로 임베딩 기능 제공\n",
    "- 이 클래스를 다른 층처럼 모델에 추가하면 처음에는 모든 벡터가 랜덤하게 초기화 되지만 훈련을 통해 데이터에서 좋은 단어 임베딩을 학습함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_KNbHczJaFP"
   },
   "source": [
    "> 단어 임베딩의 장점은 입력으로 정수 데이터를 받는다는 것\n",
    "- 즉 원-핫 인코딩으로 변경된 train_oh 배열이 아닌 train_seq을 사용할 수 있음\n",
    "- 이때문에 메모리를 훨씬 효율적으로 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwr_Bp2jJuxI"
   },
   "source": [
    "> 임베도딩 원-핫 인코딩과 비슷하게 (100,) 크기의 샘플을 (100,20)과 같이 2차원으로 늘림\n",
    "- 하지만 원-핫 인코딩과 달리 훨씬 작은 크기로도 단어를 잘 표현할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-hBOUnw7zdp"
   },
   "outputs": [],
   "source": [
    "# Embedding 클래스를 SimpleRnn 층 앞에 추가한 두 번째 순환 신경망 생성\n",
    "model2 = keras.Sequential()\n",
    "model2.add(keras.layers.Embedding(300, 16, input_length=100))\n",
    "model2.add(keras.layers.SimpleRNN(8))\n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bjn_zOUKU5o"
   },
   "source": [
    "> Embedding 클래스의 첫 번째 매개변수(300)은 어휘 사전의 크기\n",
    "\n",
    "> 두 번째 매개변수(16)는 임베딩 벡터의 크기, 여기서는 원-핫 인코딩 보다 훨씬 작은 크기 (16) 사용\n",
    "\n",
    "> 세 번째 input_length 매개변수는 입력 시퀀스의 길이, 앞서 샘플의 길이를 100으로 맞추어 train_seq을 만들었기에 이 값을 100으로 지정\n",
    "\n",
    "> 그 다음 SimpleRNN 층과 Dense 층은 이전과 동일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36HJfPBoLC2x"
   },
   "outputs": [],
   "source": [
    "# model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o4a2tVILQ66"
   },
   "source": [
    "> 이 모델은 (100,) 크기의 입력을 받아 (100,16) 크기의 출력을 만듬\n",
    "\n",
    "> 모델 파라미터 개수 계산\n",
    "- Embedding 클래스는 300개의 각 토큰을 크기가 16인 벡터로 변경하기 때문에 총 300x16 = 4800개의 모델 파라미터 층을 가짐\n",
    "- 그 다음 SimpleRNN 층은 임베딩 벡터의 크기가 16이므로 8개의 뉴런과 곱하기 위해 필요한 가중치 16 x 8 = 128개를 가짐\n",
    "- 또한 은닉 상태에 곱해지는 가중치 8 x 8 =64개가 있음\n",
    "- 마지막으로 8개의 절편을 합하면 전체 모델 파라미터의 개수는 128 + 64 + 8 = 200개\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yvqtu_GVCvJW"
   },
   "source": [
    "> 마지막 Dense 층의 가중치 개수는 이전과 동일하게 9개임\n",
    "\n",
    "> 원-핫 인코딩 보다 SimpleRNN에 주입되는 입력의 크기가 크게 줄었지만 임베딩 벡터는 단어를 잘 표현하는 능력이 있기 때문에 훈련 결과는 이전에 못지 않을 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mpf9IN-MLE3-"
   },
   "outputs": [],
   "source": [
    "# 모델 훈련 과정은 이전과 동일\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model2.compile(optimizer=rmsprop, loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5',\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model2.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
    "                     validation_data=(val_seq, val_target),\n",
    "                     callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FatkwMicDBK1"
   },
   "source": [
    "> 출력 결과를 보면 원-핫 인코딩을 사용한 모델과 비슷한 성능을 냄\n",
    "- 반면 순환층의 가중치 개수는 훨씬 작고 훈련 세트 크기도 훨씬 줄어들었음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V8BsBNsDQ12"
   },
   "outputs": [],
   "source": [
    "# 훈련 손실과 검증 손실을 그래프로 출력\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1M/8hyjIAcxeDELMPnTme",
   "gpuType": "T4",
   "mount_file_id": "1_b2lYabprZYgPNi4Phj72VUZ6k9Acs3h",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
